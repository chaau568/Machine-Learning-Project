{% extends "base.html" %} {% block title %}
<title>Emotion Details</title>
{% endblock %} {% block content %}
<div class="container mt-5">
  <h1 class="text-center mb-4">
    แบบจำลองการจำแนกอารมณ์ (Emotion Classification Model)
  </h1>

  <section class="mb-4">
    <h2>1. ข้อมูลชุด (Dataset)</h2>
    <p>
      <strong>แหล่งที่มาของข้อมูล:</strong>
      <a
        href="https://github.com/sakshisphatak/Text-Emotion-Detection/tree/main/Text%20Emotion%20Detection/data"
        target="_blank"
        >GitHub</a
      >
    </p>
    <p>
      <strong>คำอธิบายชุดข้อมูล:</strong> ชุดข้อมูลนี้ประกอบด้วย 2 คอลัมน์
      ได้แก่ คอลัมน์ "Emotion" ซึ่งระบุอารมณ์ และคอลัมน์ "Text"
      ซึ่งเป็นข้อความที่แสดงถึงอารมณ์นั้น ๆ
    </p>
    <div class="box mb-4">
      <p>แสดงจำนวนของแต่ละอารมณ์ใน dataset:</p>
      <table class="table table-bordered table-striped">
        <thead>
          <tr>
            <th>Emotion</th>
            <th>Count</th>
          </tr>
        </thead>
        <tbody>
          {% for detail in class_details %}
          <tr>
            <td>{{ detail.Emotion }}</td>
            <td>{{ detail.Count }}</td>
          </tr>
          {% endfor %}
        </tbody>
      </table>
    </div>
    <p>
      <strong>ความไม่สมบูรณ์ของข้อมูล:</strong> ข้อความในชุดข้อมูลมีสิ่งรบกวน
      ทำให้ไม่สามารถนำไปใช้กับแบบจำลองได้โดยตรง จึงต้องทำความสะอาดข้อความก่อน
      โดยใช้ไลบรารี neattext ของ Python เพื่อลบอักขระพิเศษ อีโมจิ ตัวเลข
      และจัดการข้อความซ้ำซ้อน จากนั้นใช้ CountVectorizer จากไลบรารี scikit-learn
      เพื่อแปลงข้อความเป็นเวกเตอร์ความถี่ของคำ (Bag of Words)
      เพื่อให้แบบจำลองสามารถเข้าใจได้
    </p>
  </section>

  <section class="mb-4">
    <h2>2. การแบ่งข้อมูล</h2>
    <p>ใช้ฟังก์ชัน train_test_split จากไลบรารี scikit-learn ในการแบ่งข้อมูล</p>
    <ul>
      <li>ข้อมูลสำหรับฝึก (Train): 70%</li>
      <li>ข้อมูลสำหรับทดสอบ (Test): 30%</li>
    </ul>
  </section>

  <section class="mb-4">
    <h2>3. การเลือกแบบจำลอง (Model)</h2>
    <p>ทดลองใช้หลายแบบจำลองและเปรียบเทียบค่าความแม่นยำ (Accuracy):</p>
    <ul>
      <li>Logistic Regression: 63.23%</li>
      <li>Support Vector Classification (SVC): 63.75%</li>
      <li>RandomForestClassifier: 55.40%</li>
    </ul>
    <div class="box">
      <h2>กราฟ Accuracy และ Loss ของแต่ละ Model</h2>
      <img
        src="data:image/png;base64,{{ model_accuracy }}"
        alt="Accuracy and Loss Graph"
      />
    </div>
    <p>
      เลือกใช้ Logistic Regression เนื่องจากให้ค่าความแม่นยำใกล้เคียงกับ SVC
      แต่ใช้ทรัพยากรในการฝึกน้อยกว่า
    </p>
  </section>

  <section class="mb-4">
    <h2>4. การออกแบบแบบจำลอง</h2>
    <p>
      <strong>CountVectorizer:</strong>
      เครื่องมือสำหรับแปลงข้อความเป็นเวกเตอร์ของตัวเลข
      โดยนับจำนวนการปรากฏของคำในแต่ละข้อความ
    </p>
    <ul>
      <li>สร้างคำศัพท์ (Vocabulary) และแปลงข้อความเป็นเวกเตอร์ความถี่ของคำ</li>
      <li>
        ใช้ในการแปลงข้อมูลข้อความให้เป็นรูปแบบที่แบบจำลอง Machine Learning
        สามารถประมวลผลได้
      </li>
      <li>
        ตัวอย่างการใช้งาน: แปลงข้อความ "I am happy today" เป็นเวกเตอร์ [1, 1, 1,
        1]
      </li>
    </ul>
    <p>
      <strong>Pipeline:</strong>
      กระบวนการที่รวมขั้นตอนการเตรียมข้อมูล การฝึกแบบจำลอง การทำนาย
      และการประเมินผลไว้ในขั้นตอนเดียว
    </p>
    <ul>
      <li>
        ช่วยให้การทำงานมีประสิทธิภาพ ลดความยุ่งยาก และจัดการขั้นตอนต่าง ๆ
        ได้ง่ายขึ้น
      </li>
      <li>
        รองรับการทำงานแบบอัตโนมัติ การทำ Cross-Validation และการปรับแต่ง
        Hyperparameters
      </li>
    </ul>
  </section>

  <section class="mb-4">
    <h2>5. ทฤษฎีของอัลกอริทึม</h2>
    <p>
      <strong>Logistic Regression:</strong> เป็นอัลกอริทึมที่ใช้สำหรับ
      การจำแนกประเภท (Classification) โดยเฉพาะปัญหาที่มีผลลัพธ์เป็น <br />
      ค่าไม่ต่อเนื่อง (Discrete Output) เช่น การจำแนกเป็น 0 หรือ 1 ในกรณีของ
      Binary Classification หรือ Multi-Class Classification
    </p>
    <p>
      <strong>Softmax Function:</strong>
      แปลงค่า logits เป็นค่าความน่าจะเป็นของแต่ละคลาส
      ทำให้ผลรวมของค่าความน่าจะเป็นทุกคลาสเป็น 1 <br />
      โดยจะใช้ Softmax ในการแปลงค่าผลลัพธ์จากโมเดล
      ให้เป็นความน่าจะเป็นของแต่ละคลาสในกรณีที่มี <br />
      หลายคลาส หรือ มากกว่าสองคลาส
    </p>
    <p><strong>หลังจากผ่านฟังก์ชัน Softmax ไปแล้ว เราจะได้อะไร</strong></p>
    <ul>
      <li>
        ค่าความน่าจะเป็น (Probability) <br />
        ผลลัพธ์ที่ได้จะเป็นค่าความน่าจะเป็นสำหรับแต่ละคลาส <br />
        โดยที่ค่าทุกค่าจะอยู่ระหว่าง 0 ถึง 1 และรวมกันแล้วจะเป็น 1 เช่น: <br />
        <pre>
          <b>สำหรับคลาส 1: P1=0.7P_1 = 0.7</b>
          <b>สำหรับคลาส 2: P2=0.2P_2 = 0.2</b>
          <b>สำหรับคลาส 3: P3=0.1P_3 = 0.1</b>
        </pre>
      </li>
      <li>
        การเลือกคลาสที่ดีที่สุด <br />
        จากค่าความน่าจะเป็นที่ได้เราสามารถเลือกคลาสที่มีความน่าจะเป็นสูงที่สุดเป็นผลลัพธ์ที่โมเดลคาดการณ์ได้
        <br />
        โดยในตัวอย่างนี้ โมเดลจะเลือกคลาส 1 เนื่องจากมีความน่าจะเป็นสูงสุดที่
        0.7
      </li>
    </ul>
    <p>
      <strong>Loss Function:</strong>
      วัดความแตกต่างระหว่างค่าที่คาดการณ์และค่าจริง
      ใช้ในการปรับพารามิเตอร์ของแบบจำลองให้มีค่าความแม่นยำสูงขึ้น
    </p>
    <p>
      Loss Function มีจุดประสงค์หลักในการ ประเมินประสิทธิภาพของโมเดล <br />
      โดยการเปรียบเทียบค่าทำนายที่โมเดลคำนวณได้กับค่าจริงที่เรามีในชุดข้อมูล
    </p>
    <ul>
      <li>ถ้าค่าทำนายใกล้เคียงกับค่าจริง Loss จะน้อย</li>
      <li>ถ้าค่าทำนายต่างจากค่าจริงมาก Loss จะมาก</li>
    </ul>
    <p><strong>หลังจากผ่าน Loss Function ไปแล้ว จะได้อะไร</strong></p>
    <ul>
      <li>
        เมื่อค่าของ Loss ต่ำลง
        หมายความว่าโมเดลเริ่มคาดการณ์ได้ใกล้เคียงกับค่าจริงมากขึ้น
      </li>
      <li>
        โมเดลจะ ปรับพารามิเตอร์ (เช่น น้ำหนักในกรณีของ Neural Networks) <br />
        เพื่อทำให้ Loss ลดลง ผ่านกระบวนการ Gradient Descent หรือ Optimization
        อื่น ๆ
      </li>
    </ul>
    <p>
      <strong>Gradient Descent:</strong>
      อัลกอริทึมสำหรับหาค่าพารามิเตอร์ที่เหมาะสมที่สุด
      โดยการปรับค่าพารามิเตอร์ในทิศทางที่ลดค่า Loss Function
    </p>
    <p>
      การทำงานของ Gradient Descent คือการเดินตาม ทางลาด ของฟังก์ชันการสูญเสีย
      โดยเริ่มจากจุดเริ่มต้น (มักจะเริ่มจากค่าพารามิเตอร์สุ่ม) <br />
      และค่อยๆ ปรับพารามิเตอร์ไปในทิศทางที่ทำให้ฟังก์ชันการสูญเสียมีค่าต่ำที่สุด
    </p>
    <p><strong>สิ่งที่ได้หลังจากผ่าน Gradient Descent</strong></p>
    <ul>
      <li>
        ค่าพารามิเตอร์ที่ดีที่สุด (Optimal Parameters): <br />
        ค่าพารามิเตอร์ (เช่น weights และ biases)
        ที่ทำให้ฟังก์ชันการสูญเสียมีค่าต่ำสุด <br />
        หรือ โมเดลที่สามารถทำการทำนายได้ดีที่สุด
      </li>
      <li>
        โมเดลที่ฝึกเสร็จสมบูรณ์: <br />
        โมเดลที่มีการเรียนรู้จากข้อมูลและสามารถทำนายข้อมูลใหม่ได้อย่างแม่นยำ
      </li>
    </ul>
  </section>

  <section class="mb-4">
    <h2>6. การบันทึกผลการฝึกแบบจำลอง</h2>
    <p>
      ใช้ <code>pickle.dump</code> ในการบันทึกข้อมูลการฝึกเป็นไฟล์ .pkl โดย .pkl
      คือ ไฟล์ที่ใช้บันทึกออบเจ็กต์ Python ในรูปแบบของ Pickle <br />
      ซึ่งเป็นกระบวนการ serialize (บันทึก) และ deserialize (โหลดกลับมาใช้)
      ออบเจ็กต์ใน Python
      ซึ่งช่วยให้ไม่ต้องฝึกโมเดลทุกครั้งที่ต้องทำนายผลข้อมูลใหม่ๆ
    </p>
  </section>
</div>

<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.3/dist/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
{% endblock %}
